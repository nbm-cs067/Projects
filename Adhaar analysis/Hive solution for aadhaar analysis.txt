[cloudera@quickstart ~]$ sh Start-HIVE.sh 
Starting Hive Metastore (hive-metastore):                  [  OK  ]
Started Hive Server2 (hive-server2):                       [  OK  ]
hive (adhaar_db)> create table adhaar_details_tbl (Registrar varchar(500),Enrolment_Agency varchar(500),State varchar(500),District varchar(500),Sub_District varchar(500),PinCode double,Gender varchar(1),Age int,adhaar_generated int,Enrolment_Rejected int,Residents_providing_email int,Residents_providing_mobile_number int) row format delimited fields terminated by ',';
OK
Time taken: 0.131 seconds
hive (adhaar_db)> load data local inpath '/home/cloudera/Desktop/Adhar Analysis/UIDAI-ENR-DETAIL-20170308.csv' into adhaar_details_tbl;
FAILED: ParseException line 1:98 missing TABLE at 'adhaar_details_tbl' near '<EOF>'
hive (adhaar_db)> load data local inpath '/home/cloudera/Desktop/Adhar Analysis/UIDAI-ENR-DETAIL-20170308.csv' into table adhaar_details_tbl;
Loading data to table adhaar_db.adhaar_details_tbl
Table adhaar_db.adhaar_details_tbl stats: [numFiles=1, totalSize=46483335]
OK
Time taken: 2.356 seconds
hive (adhaar_db)> select * from adhaar_details_tbl limit 10;
OK
adhaar_details_tbl.registrar	adhaar_details_tbl.enrolment_agency	adhaar_details_tbl.state	adhaar_details_tbl.district	adhaar_details_tbl.sub_district	adhaar_details_tbl.pincode	adhaar_details_tbl.gender	adhaar_details_tbl.age	adhaar_details_tbl.adhaar_generated	adhaar_details_tbl.enrolment_rejected	adhaar_details_tbl.residents_providing_email	adhaar_details_tbl.residents_providing_mobile_number
Registrar	Enrolment Agency	State	District	Sub District	NULL	G	NULL	NULL	NULL	NULL	NULL
Allahabad Bank	A-Onerealtors Pvt Ltd	Uttar Pradesh	Allahabad	Meja	212303.0	F	7	1	0	0	1
Allahabad Bank	Asha Security Guard Services	Uttar Pradesh	Sonbhadra	Robertsganj	231213.0	M	8	1	0	0	0
Allahabad Bank	SGS INDIA PVT LTD	Uttar Pradesh	Sultanpur	Sultanpur	227812.0	F	13	1	0	0	1
Allahabad Bank	Sri Ramraja Sarkar Lok Kalyan Trust	Uttar Pradesh	Shamli	Shamli	247775.0	M	6	1	0	0	1
Allahabad Bank	Transmoovers India	Uttar Pradesh	Gorakhpur	Sahjanwa273001.0	M	8	1	0	0	1
Allahabad Bank	Transmoovers India	Uttar Pradesh	Varanasi	Pindra	221101.0	M	14	1	0	0	1
Allahabad Bank	Transmoovers India	Uttar Pradesh	Varanasi	Varanasi221001.0	M	9	1	0	0	1
Allahabad Bank	Transmoovers India	Uttar Pradesh	Varanasi	Varanasi221002.0	M	4	1	0	0	1
Allahabad Bank	Transmoovers India	Uttar Pradesh	Varanasi	Varanasi221002.0	M	10	0	1	0	1
Time taken: 0.151 seconds, Fetched: 10 row(s)
hive (adhaar_db)> select count(*) as count,State from adhaar_details_tbl group by State order by count DESC;
Query ID = cloudera_20200108041010_26b483cd-5fce-4dcd-9c8d-c8008d84505e
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0002, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0002/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0002
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-01-08 04:10:12,278 Stage-1 map = 0%,  reduce = 0%
2020-01-08 04:10:22,034 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 6.25 sec
2020-01-08 04:10:31,840 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 10.09 sec
MapReduce Total cumulative CPU time: 10 seconds 90 msec
Ended Job = job_1578469779176_0002
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0003, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0003/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0003
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2020-01-08 04:10:44,093 Stage-2 map = 0%,  reduce = 0%
2020-01-08 04:10:51,609 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.44 sec
2020-01-08 04:11:01,309 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 6.1 sec
MapReduce Total cumulative CPU time: 6 seconds 100 msec
Ended Job = job_1578469779176_0003
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 10.09 sec   HDFS Read: 46492560 HDFS Write: 1259 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 6.1 sec   HDFS Read: 6186 HDFS Write: 594 SUCCESS
Total MapReduce CPU Time Spent: 16 seconds 190 msec
OK
count	state
81776	Bihar
69476	Uttar Pradesh
60485	West Bengal
37360	Madhya Pradesh
28659	Rajasthan
24146	Gujarat
21196	Tamil Nadu
19783	Maharashtra
15755	Karnataka
12378	Kerala
11972	Odisha
7423	Jharkhand
7247	Delhi
6521	Uttarakhand
5888	Punjab
5138	Haryana
4617	Chhattisgarh
4540	Andhra Pradesh
3768	Telangana
3172	Mizoram
2972	Assam
1331	Jammu and Kashmir
1283	Himachal Pradesh
799	Goa
726	Tripura
632	Arunachal Pradesh
562	Manipur
392	Nagaland
259	Meghalaya
199	Chandigarh
107	Dadra and Nagar Haveli
99	Daman and Diu
85	Puducherry
48	Sikkim
12	Others
7	Andaman and Nicobar Islands
5	Lakshadweep
1	State
Time taken: 60.968 seconds, Fetched: 38 row(s)
hive (adhaar_db)> select count(*) as count,enrolment_agency from adhaar_details_tbl group by enrolment_agency order by count DESC;
Query ID = cloudera_20200108041212_d9c8dcf6-7b58-4bae-b55b-046449ca4197
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0004, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0004/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0004
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-01-08 04:12:26,496 Stage-1 map = 0%,  reduce = 0%
2020-01-08 04:12:38,385 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 8.02 sec
2020-01-08 04:12:48,158 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 11.81 sec
MapReduce Total cumulative CPU time: 11 seconds 810 msec
Ended Job = job_1578469779176_0004
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0005, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0005/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0005
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2020-01-08 04:13:00,820 Stage-2 map = 0%,  reduce = 0%
2020-01-08 04:13:09,364 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.96 sec
2020-01-08 04:13:18,989 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 6.56 sec
MapReduce Total cumulative CPU time: 6 seconds 560 msec
Ended Job = job_1578469779176_0005
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 11.81 sec   HDFS Read: 46492582 HDFS Write: 15608 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 6.56 sec   HDFS Read: 20557 HDFS Write: 10391 SUCCESS
Total MapReduce CPU Time Spent: 18 seconds 370 msec
OK
count	enrolment_agency
100357	CSC SPV
18101	SRM Education And Social Welfare Society
16972	SREI INFRASTRUCTURE FINANCES L
12910	Rajcomp Info Services Ltd
12580	AKSH OPTIFIBRE LIMITED
12114	TAMILNADU ARASU CABLE TV CORPORATION LTD
11937	Akshaya
10808	MPOnline Limited
9229	CMS Computers Ltd
7537	IAP COMPANY Pvt. Ltd
6905	NPS Technologies Pvt. Ltd
6334	Karvy Data Management Services
6175	Wipro Ltd
5949	Zephyr System Pvt.Ltd.
5916	BASIX
5359	Computer LAB
4833	AISECT Limited
4654	Vedavaag Systems Limited
4501	Centre for e-Governance  GOK
4497	A I Soc for Electronics and Comp Tech
4355	Amar Constructions
4183	Netlink software Pvt Ltd
4069	Nielsen  India  Private Limited
4005	Twinstar Industries Ltd.
3958	Directorate of ESD
3856	CHIPS
3706	FINANCIAL INFORMATION NETWORK
3474	Home Life Buildcon Pvt Ltd
3454	Vakrangee Softwares Limited
3424	Alankit Limited
3354	Electronics Corporation of Tamil Nadu Limited
3347	SGS INDIA PVT LTD
3004	Utility Forms Pvt Ltd
2986	Nekton IT India Pvt Ltd.
2813	Abha Systems And Consultancy
2709	RELIGARE SECURITIES LTD
2692	Make India Smart Private Limited
2654	BNK Capital Markets Limited
2615	Indotech Engineering Products
2590	National Cooperative Consumers Federation of India Limited
2487	Synapses Solutions Private Limited
2453	Techno Bytes Information Pvt. Ltd
2438	Prakash Computer Services
2432	Mahamritunjay Traders
2428	VEETECHNOLOGIES PVT. LTD
2144	Sarvalabh Global Foundation
2124	Sri Ramraja Sarkar Lok Kalyan Trust
1860	IPS e Services Pvt Ltd
1813	M/s Gold Square Builders & Promoters Pvt. Ltd.
1776	Omnitech Infosolutions Ltd
1727	AVVAS INFOTECH PVT  LTD
1683	LYRA  CONSULTANCY SERVICE
1680	Radiant Haroti Industries India Ltd
1658	A-Onerealtors Pvt Ltd
1575	N.K. Sharma Enterprises Ltd.
1548	Network for Information & Computer
1543	Matrix Processing House
1539	Estex Telecom Pvt Ltd
1495	Gujarat Infotech Ltd.
1458	Atalji Janasnehi Directorate  GOK
1440	RBS multisolutions private limited
1382	Promind Solutions P Limited
1361	DATASOFT COMPUTER SERVICES(P)
1293	Digitcom Systems Pvt. Ltd.
1272	United Telecoms Ltd
1259	CSC e-Governance Services India Limited
1236	KDS Services Private Limited
1223	Squaria Global India Private Limited
1104	Ecartes Technology Pvt. Ltd
1087	Janta Silikon Consortium
1083	Seva Society Collector Kutch
991	Super Printers
991	Eagle Software India Pvt. Ltd
988	Bloom Solutions Pvt Ltd
985	VISION COMPTECH INTEGRATOR LTD
895	Agro Tech Engineers
881	Saket Advertising Pvt. Ltd
843	E Seva Society UID Kheda Nadiad
818	EDCS GOK
773	OSWAL COMPUTERS & CONSULTANTS
746	Steel City Securities Limited
733	E-Seva Society UID Bharuch
732	SRR Infotech
732	Osiris Infotech Pvt. Ltd.
724	Late Smt. Nirmala Singh Seva Samiti
700	Asha Security Guard Services
697	District E-Seva Society Navsari
690	Jilla E-seva Society Banaskantha
670	VIRGO SOFTECH LIMITED
666	E-Seva Society Bhavnagar
644	M/s TAVASYA VENTURE PARTNERS PVT. LTD.
640	District E-Seva Society Panchmahals Godhra
638	M/s. Goa Electronics Ltd
637	COMTECHINFO SOLUTIONS PVT.LTD
636	Dist E-seva Society Anand
633	Emdee Digitronics Pvt.Ltd.
631	Deputy Commissioner  Aizawl
628	Jilla E-seva Sadan  Dahod
615	Virinchi Technologies Ltd
608	Yuvaan Infotech
597	Mahaonline Limited
591	Jilla E-Seva Society Sabarkantha
583	Department of IT  Govt. of HP
582	Sixth Dimension Project Solutions Ltd
578	DC Lunglei
560	UID e-Seva Society Ahmedabad
558	KRISHNAURAM SHIKSHA EVAM JAN KALYAN SAMITI
544	SARADA SYSTEMS
534	Municipal Corporation Ahmedabad
518	City Hawks Manpower Services & Consultancy
509	PROTEX COMPUTER PVT LTD
478	Raj Construction Co.
471	Academy of Management Studies
466	District E-Seva Society Gandhinagar
465	E-Seva Society Amreli
464	Department of Information Technology and e-Gov  Government of Jharkhand
461	WEBEL TECHNOLOGY LIMITED
450	Jilla E-Seva Society Rajkot
449	Munish Kumar Bansal Contractor
435	Nevaeh Technology Pvt. Ltd.
433	Conatus Infocom Pvt. Ltd
419	DC Serchhip
415	Vayam technologies Ltd
414	VAP INFOSOLUTIONS
407	CALANCE SOFTWARE PRIVATE LTD
405	Yash Ornaments Pvt. Ltd
404	E-Seva Society Jamnagar
394	Layman Education Society
393	Shubh Enterprises
368	M/s Sanish Choudhary
366	Jilla E-Seva Society Valsad
355	Akhil Bhartiya Majdoor Shiksha Sewa Samiti
350	E-Seva Society Surendranagar
350	D.C. Champhai
349	HI-TECH CONTROLS
349	E-Seva Society Arvalli
348	Dist. E-seva Society Morbi
343	Deputy Commissioner Kolasib
339	DC Mamit
323	E-Seva Society Junagadh
319	Care Educational & Welfare Society
315	e-Seva Society  Chhotaudepur
310	MEGHA VINCOM PVT LTD
295	NVR & ASSOCIATES LIMITED
286	DC Siaha
278	APOnline Limited
278	Limra Global e Services Private Limited
274	Deputy Commissioner  Lawngtlai
273	Om Softwares
238	Orion Security Solutions Private Ltd
235	VISESH INFOTECNICS LIMITED
231	MANTRA SOFTTECH (INDIA) PVTLTD
220	Apnatech Consultancy Services Pvt Ltd
219	Directorate of Women & Child Department  Govt Of Goa
211	ATISHAY INFOTECH PVT. LTD.
209	SoftAge Information Technology Limited
208	E-Seva Society UID Patan
208	Jeevan Deep Charitable Society
200	District e-Seva Society Botad
199	Computer Print
197	SVG Express Services Pvt Ltd
197	Frontech Systems Pvt Ltd
192	Ojus Healthcare Private Limited
190	MKS Enterprises
190	India Computer Technology
188	UT Computers Educational & Welfare Soc
187	E-Seva Society Collector Office Tapi Vyara
183	District IT Society Gurgaon
180	BNR UDYOG LIMITED
177	Bhaswa Computer Science Pvt. Ltd.
176	Tera Software Ltd
172	Organisation for Development Integrated Social & Health Action  ODISHA
165	State Health Society
165	Mahanagar Seva Sadan Vadodara
162	Urmila Info solution
150	District E-Seva Society Surat
149	Binary Systems
147	District Magistrate & Collector  West Tripura District
143	COMTECH INSTITUTE OFTECHNOLOGY
141	District Magistrate & Collector Sepahijala District
139	District IT Society Sirsa
134	Advent Infomax Private Ltd
133	Blue Circle Instrument
131	Wedha Communication Pvt Ltd
130	Corporate India Facilities Pvt Ltd
126	DC office Aalo
119	Transline Technologies P Ltd
118	In Media Computer Services LLP
117	SRM Techsol Pvt. Ltd.
116	District Magistrate & Collector  Gomati District
113	APEX Services
108	e-Seva Society UID Dang
107	Jamnagar MC
106	Jilla e-SEVA society Gir Somnath
106	District IT Society Faridabad
105	District IT Society Rohtak
104	District IT Society Hisar
103	Rajkot Municipal Corporation
102	77 Infosystems Pvt Ltd
102	District IT Society Karnal
95	Silver Touch Technologies Ltd
95	Department of IT  Chandigarh
94	District IT Society Bhiwani
91	SAR Technology
90	Offshoot Agency Pvt. Ltd.
90	Surat Municipal Corporation
89	District IT Society Mahendragarh
86	CHESSY CONSULTANTS PVT LTD
85	M/S King Computer System pvt Ltd
84	District IT Society Mewat
83	District E-Seva Society Mehsana
82	District IT Society Rewari
78	Aayam Enterprises
77	District IT Society Panchkula
76	M/S STAR DATA CENTRE
76	District IT Society Panipat
75	Ojus G Enterprises
71	AS International
70	SILVER JUBILEE MOTORS LTD.
66	District IT Society Sonipat
63	CIRCLE OFFICER PIYONG
62	District IT Society Ambala
62	Compro Systems & Services
62	Abhipra Capital Ltd
62	Jilla e-SEVA Society Devbhoomi Dwarka
61	District IT Society Yamuna Nagar
59	M2C Private Solution
56	DDSE Lohit
56	Sant Naval Institute of Information Technology
54	District IT Society Palwal
53	District Magistrate & Collector  Unakoti  District
51	M/s. Vidya Online  Pune
51	Asray Gram
50	UT of Daman and Diu
48	District IT Society Kurukshetra
48	District Magistrate &  Collector  Dhalai District
47	District Magistrate & Collector  South Tripura
46	Lankipalli Integrated Services Private Limited
46	BHAVANAGAR MC
46	Business Information Processing Services
46	CDPO Tezu ICDS
46	District IT Society Jhajjar
46	Administration of DNH
46	Jilla E-Seva Society Vadodara
45	JNET Technologies Pvt.Ltd
45	Sanghavi Computer Centre Private Ltd
41	District Magistrate & Collector  NorthTripura District
39	Women and Child Development
37	District IT Society Kaithal
36	EAC FI DA CHONGKHAM
35	Karvy Computershare Private Li
35	Mahisagar Lunawala
34	DSO STAT NAMSAI
34	District Sukhmani Society Fatehgarh Sahib Punjab
33	Director  Woman and Child Development  Govt. of Himachal Pradesh
32	Department of Economics Statistics  Monitoring and Evaluation DESME
31	SREEVEN INFOCOM LIMITED
29	UMC Technologies Pvt. Ltd
28	M/s Smit Advertisers Pvt. Ltd.
28	Patel Computer Education
28	SNR Edatas Pvt Ltd
27	United Telecoms e-Services Pvt Ltd
26	District IT Society Fatehabad
26	HyperSoft Technologies Ltd
25	Municipal Corporation Gandhinagar
25	Punjab State e- Governance Society
25	DC Wokha
23	Directorate of Public Health and Family Welfare  Govt of Andhra Pradesh
22	Extra Assistant Commissioner Naharlagun
21	EAC LEKANG
21	E-Seva Society Narmada Rajpipla
21	eCentric solutions pvt ltd
19	CO JOMLO MOBUK
19	UIDAI-EA
18	District Sukhmani Society For Citizen Services Mansa Punjab
17	Smart Chip Limited
17	DFCSO  Tezu
16	District Sukhmani Society  Ludhiana  Punjab
16	Pho-com-net Pvt. Ltd.
16	Extra Assistant Commissioner Itanagar
15	Circle Officer Toru
14	EAC OFFICE KAYING/CO PAYUM
14	Clairvoyance Technologies Pvt.
13	S.J. Technologies
13	District Magistrate & Collector  Khowai District
12	Rural Environment & Water Assets Reproductive Development Society
11	Multiwave Innovation
10	Junagadh MC
10	Bhartiya Manav Kalyan Parishad
10	Arya bandhu herbs and durgs private limited
9	MACRO INFOTECH PVT LTD
8	SETU MAHARASHTRA
7	Viesa Technologies
7	District Sukhmani Society Sangrur Punjab
6	Transmoovers India
6	District Sukhmani Society Fazilka Punjab
6	Yashi Informatics LLP
5	ADC BOLENG
4	District Sukhmani Society Bathinda Punjab
4	Excel Technovation Pvt. Ltd
4	DEVASHISH SECURITIES PVT. LTD.
4	Chinar Construction Company Prime agency
4	Alankit Finsec Ltd
3	UNITED DATA SERVICES PRIVATE LIMITED
3	Pariza Enterprises
3	Manipur Electronics Dev Corp
3	MARS Telecom Systems Pvt Ltd
3	E-Seva Society Porbandar
2	SPANCO
2	District Sukhmani Society Tarn Taran Punjab
2	TechSmart India Pvt Ltd
2	Madras Security Printers Ltd
2	Ricoh India Limited
1	SHRIKRISHNA KHANDASARI SUGAR M
1	District Sukhmani Society Amritsar Punjab
1	Quick Data IT Services Pvt Ltd
1	Planning and Research Department
1	DIT Lakshadweep
1	Enrolment Agency
1	District Family & Welfare Society Palwal
1	District Family and Welfare Society  Jhajjar
1	VIKALP MULTIMEDIA
1	District Health and Family Welfare Society Fatehabad
1	WEBEL
1	District IT Society Jind
1	Integrated Systems & Services
Time taken: 64.239 seconds, Fetched: 326 row(s)
hive (adhaar_db)> select count(*) as count,district from adhaar_details_tbl group by district order by count DESC limit 10;
Query ID = cloudera_20200108041414_cc37c6e1-96fb-40b8-a15b-1afbd3d01c5d
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0006, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0006/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0006
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-01-08 04:15:02,816 Stage-1 map = 0%,  reduce = 0%
2020-01-08 04:15:15,666 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 8.44 sec
2020-01-08 04:15:24,215 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 12.2 sec
MapReduce Total cumulative CPU time: 12 seconds 200 msec
Ended Job = job_1578469779176_0006
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0007, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0007/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0007
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2020-01-08 04:15:36,666 Stage-2 map = 0%,  reduce = 0%
2020-01-08 04:15:45,314 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 3.67 sec
2020-01-08 04:15:55,175 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 8.05 sec
MapReduce Total cumulative CPU time: 8 seconds 50 msec
Ended Job = job_1578469779176_0007
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 12.2 sec   HDFS Read: 46492567 HDFS Write: 19409 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 8.05 sec   HDFS Read: 24463 HDFS Write: 152 SUCCESS
Total MapReduce CPU Time Spent: 20 seconds 250 msec
OK
count	district
7135	Barddhaman
6894	North 24 Parganas
6078	South 24 Parganas
5287	Bhagalpur
5251	Patna
5133	Nadia
4417	Murshidabad
4402	Gaya
4067	Kolkata
3974	Katihar
Time taken: 63.562 seconds, Fetched: 10 row(s)
hive (adhaar_db)> select count(*) as count,district,gender from adhaar_details_tbl group by district having gender='M' order by count DESC limit 10;
FAILED: SemanticException [Error 10025]: Line 1:90 Expression not in GROUP BY key ''M''
hive (adhaar_db)> select count(*) as count,district,gender from adhaar_details_tbl group by district having gender=M order by count DESC limit 10;
FAILED: SemanticException [Error 10025]: Line 1:90 Expression not in GROUP BY key 'M'
hive (adhaar_db)> select count(*) as count,district,gender from adhaar_details_tbl group by district,gender order by count DESC limit 10;
Query ID = cloudera_20200108041919_5b1f2ac1-544e-4af2-a722-18f65f075ea7
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0008, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0008/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0008
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-01-08 04:19:29,537 Stage-1 map = 0%,  reduce = 0%
2020-01-08 04:19:40,435 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 6.82 sec
2020-01-08 04:19:50,223 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 11.24 sec
MapReduce Total cumulative CPU time: 11 seconds 240 msec
Ended Job = job_1578469779176_0008
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0009, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0009/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0009
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2020-01-08 04:20:02,542 Stage-2 map = 0%,  reduce = 0%
2020-01-08 04:20:13,453 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 6.3 sec
2020-01-08 04:20:22,059 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 10.29 sec
MapReduce Total cumulative CPU time: 10 seconds 290 msec
Ended Job = job_1578469779176_0009
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 11.24 sec   HDFS Read: 46492963 HDFS Write: 40519 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 10.29 sec   HDFS Read: 45921 HDFS Write: 185 SUCCESS
Total MapReduce CPU Time Spent: 21 seconds 530 msec
OK
count	district	gender
4276	Barddhaman	M
3772	North 24 Parganas	M
3630	South 24 Parganas	M
3543	Bhagalpur	M
3485	Patna	M
3460	Nadia	M
3121	North 24 Parganas	F
3018	Murshidabad	M
2915	Gaya	M
2859	Barddhaman	F
Time taken: 64.006 seconds, Fetched: 10 row(s)
hive (adhaar_db)> select Sum(*) as Sumofcount,State from adhaar_details_tbl group by State order by count DESC limit 10;
FAILED: SemanticException The specified syntax for UDAF invocation is invalid.
hive (adhaar_db)> select sum(*) as Sumofcount,State from adhaar_details_tbl group by State order by count DESC limit 10;
FAILED: SemanticException The specified syntax for UDAF invocation is invalid.
hive (adhaar_db)> select sum(*) as Sumofcount,State from adhaar_details_tbl group by State order by count DESC;
FAILED: SemanticException The specified syntax for UDAF invocation is invalid.
hive (adhaar_db)> select sum(*) as sumofcount,State from adhaar_details_tbl group by State order by sumofcount DESC limit 10;
FAILED: SemanticException The specified syntax for UDAF invocation is invalid.
hive (adhaar_db)> select SUM(*) as sumofcount,State from adhaar_details_tbl group by State order by sumofcount DESC limit 10;
FAILED: SemanticException The specified syntax for UDAF invocation is invalid.
hive (adhaar_db)> select SUM('Aadhaar_generated') as sumofcount,State from adhaar_details_tbl group by State order by sumofcount DESC limit 10;
Query ID = cloudera_20200108042525_2af6c547-08d3-452d-9aa8-b3500837462a
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0010, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0010/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0010
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-01-08 04:26:05,881 Stage-1 map = 0%,  reduce = 0%
2020-01-08 04:26:18,675 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 7.88 sec
2020-01-08 04:26:28,329 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 11.63 sec
MapReduce Total cumulative CPU time: 11 seconds 630 msec
Ended Job = job_1578469779176_0010
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0011, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0011/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0011
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2020-01-08 04:26:39,810 Stage-2 map = 0%,  reduce = 0%
2020-01-08 04:26:47,319 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.05 sec
2020-01-08 04:26:55,844 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 5.57 sec
MapReduce Total cumulative CPU time: 5 seconds 570 msec
Ended Job = job_1578469779176_0011
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 11.63 sec   HDFS Read: 46492738 HDFS Write: 1464 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 5.57 sec   HDFS Read: 6526 HDFS Write: 137 SUCCESS
Total MapReduce CPU Time Spent: 17 seconds 200 msec
OK
sumofcount	state
0.0	West Bengal
0.0	Uttarakhand
0.0	Uttar Pradesh
0.0	Tripura
0.0	Telangana
0.0	Tamil Nadu
0.0	State
0.0	Sikkim
0.0	Rajasthan
0.0	Punjab
Time taken: 60.775 seconds, Fetched: 10 row(s)
hive (adhaar_db)>  select SUM(`Aadhaar_generated`) as sumofcount,State from adhaar_details_tbl group by State order by sumofcount DESC limit 10;
FAILED: SemanticException [Error 10004]: Line 1:12 Invalid table alias or column reference 'Aadhaar_generated': (possible column names are: registrar, enrolment_agency, state, district, sub_district, pincode, gender, age, adhaar_generated, enrolment_rejected, residents_providing_email, residents_providing_mobile_number)
hive (adhaar_db)>  select SUM(`adhaar_generated`) as sumofcount,State from adhaar_details_tbl group by State order by sumofcount DESC limit 10;
Query ID = cloudera_20200108043030_39906f38-4cdb-46a8-a07c-6a5fec519cd4
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0012, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0012/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0012
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-01-08 04:30:33,932 Stage-1 map = 0%,  reduce = 0%
2020-01-08 04:30:42,786 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.17 sec
2020-01-08 04:30:51,352 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 8.47 sec
MapReduce Total cumulative CPU time: 8 seconds 470 msec
Ended Job = job_1578469779176_0012
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0013, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0013/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0013
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2020-01-08 04:31:04,296 Stage-2 map = 0%,  reduce = 0%
2020-01-08 04:31:13,114 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 5.2 sec
2020-01-08 04:31:22,766 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 9.2 sec
MapReduce Total cumulative CPU time: 9 seconds 200 msec
Ended Job = job_1578469779176_0013
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 8.47 sec   HDFS Read: 46492628 HDFS Write: 1261 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 9.2 sec   HDFS Read: 6319 HDFS Write: 168 SUCCESS
Total MapReduce CPU Time Spent: 17 seconds 670 msec
OK
sumofcount	state
162607	Bihar
119901	West Bengal
103767	Uttar Pradesh
53276	Madhya Pradesh
39570	Rajasthan
34844	Gujarat
32485	Tamil Nadu
26085	Maharashtra
19764	Karnataka
18182	Odisha
Time taken: 60.826 seconds, Fetched: 10 row(s)
hive (adhaar_db)> select SUM(`adhaar_generated`) as total,district,gender from adhaar_details_tbl group by district,gender order by count DESC limit 10;
FAILED: SemanticException [Error 10004]: Line 1:114 Invalid table alias or column reference 'count': (possible column names are: total, district, gender)
hive (adhaar_db)> select SUM(`adhaar_generated`) as total,district,gender from adhaar_details_tbl group by district,gender order by total DESC limit 10;
Query ID = cloudera_20200108043232_cb6e3349-035b-4656-a7bc-1081d937ad9d
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0014, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0014/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0014
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-01-08 04:33:05,691 Stage-1 map = 0%,  reduce = 0%
2020-01-08 04:33:17,624 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 6.69 sec
2020-01-08 04:33:27,258 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 10.8 sec
MapReduce Total cumulative CPU time: 10 seconds 800 msec
Ended Job = job_1578469779176_0014
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0015, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0015/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0015
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2020-01-08 04:33:38,289 Stage-2 map = 0%,  reduce = 0%
2020-01-08 04:33:42,451 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 0.89 sec
2020-01-08 04:33:47,617 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.2 sec
MapReduce Total cumulative CPU time: 2 seconds 200 msec
Ended Job = job_1578469779176_0015
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 10.8 sec   HDFS Read: 46493035 HDFS Write: 40723 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.2 sec   HDFS Read: 46125 HDFS Write: 194 SUCCESS
Total MapReduce CPU Time Spent: 13 seconds 0 msec
OK
total	district	gender
11007	Bhagalpur	M
9744	Barddhaman	F
8382	South 24 Parganas	F
7825	South 24 Parganas	M
6968	Katihar	M
6808	Murshidabad	M
6195	Samastipur	M
6191	Patna	M
6108	North 24 Parganas	F
6077	Barddhaman	M
Time taken: 53.968 seconds, Fetched: 10 row(s)
hive (adhaar_db)>  select count(case when gender='M' then 1 end) as malecnt,count(case when gender='F' then 1 end) as femalecnt,district from adhaar_details_tbl group by district order by malecnt DESC,femalecnt DESC;
Query ID = cloudera_20200108204545_c085867c-e4d5-49ea-8541-d32c84c2db1d
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0016, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0016/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0016
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-01-08 20:46:11,233 Stage-1 map = 0%,  reduce = 0%
2020-01-08 20:46:27,696 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.34 sec
2020-01-08 20:46:38,455 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.61 sec
MapReduce Total cumulative CPU time: 17 seconds 610 msec
Ended Job = job_1578469779176_0016
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1578469779176_0017, Tracking URL = http://localhost:8088/proxy/application_1578469779176_0017/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1578469779176_0017
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2020-01-08 20:46:49,824 Stage-2 map = 0%,  reduce = 0%
2020-01-08 20:46:58,554 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 3.08 sec
2020-01-08 20:47:07,069 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 7.08 sec
MapReduce Total cumulative CPU time: 7 seconds 80 msec
Ended Job = job_1578469779176_0017
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.61 sec   HDFS Read: 46494014 HDFS Write: 20478 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 7.08 sec   HDFS Read: 25782 HDFS Write: 11087 SUCCESS
Total MapReduce CPU Time Spent: 24 seconds 690 msec
OK
malecnt	femalecnt	district
4276	2859	Barddhaman
3772	3121	North 24 Parganas
3630	2448	South 24 Parganas
3543	1744	Bhagalpur
3485	1766	Patna
3460	1673	Nadia
3018	1399	Murshidabad
2915	1487	Gaya
2678	1388	Kolkata
2622	1352	Katihar
2522	1195	Samastipur
2371	1370	Bhojpur
2265	1140	Jaipur
2219	1092	Ahmedabad
2181	1327	Bengaluru
2174	1248	Khagaria
2099	966	East Champaran
2084	937	West Champaran
2053	1003	Munger
1933	618	Madhubani
1920	798	Darbhanga
1904	1509	Jalpaiguri
1883	872	Nalanda
1830	886	Sitamarhi
1800	1005	Allahabad
1780	925	Malda
1631	755	Saran
1619	910	Rohtas
1585	1347	Paschim Medinipur
1536	1393	Howrah
1503	707	Jaunpur
1455	151	Malappuram
1392	671	Mumbai Suburban
1374	554	Lucknow
1351	817	Uttar Dinajpur
1345	809	Ghaziabad
1332	646	Gopalganj
1295	514	Vaishali
1291	570	Jodhpur
1279	243	Thiruvananthapuram
1270	692	Surat
