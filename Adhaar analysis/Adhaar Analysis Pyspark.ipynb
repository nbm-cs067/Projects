{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark \n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext,SparkConf\n",
    "conf=SparkConf()\n",
    "sc=SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HiveContext' from 'pyspark.sql' (C:\\Users\\nbhatm\\Downloads\\Softwares\\spark-3.0.0-preview-bin-hadoop2.7\\spark-3.0.0-preview-bin-hadoop2.7\\python\\pyspark\\sql\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-7b873fa2b1d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSparkSession\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mHiveContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mspark_sql_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'aadhaar_analysis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menableHiveSupport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msqlcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHiveContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'HiveContext' from 'pyspark.sql' (C:\\Users\\nbhatm\\Downloads\\Softwares\\spark-3.0.0-preview-bin-hadoop2.7\\spark-3.0.0-preview-bin-hadoop2.7\\python\\pyspark\\sql\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext,SparkSession,HiveContext\n",
    "spark_sql_context=SparkSession.builder.appName('aadhaar_analysis').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+---------+------------+--------+------+---+-----------------+------------------+-------------------------+---------------------------------+\n",
      "|     Registrar|    Enrolment Agency|        State| District|Sub District|Pin Code|Gender|Age|Aadhaar generated|Enrolment Rejected|Residents providing email|Residents providing mobile number|\n",
      "+--------------+--------------------+-------------+---------+------------+--------+------+---+-----------------+------------------+-------------------------+---------------------------------+\n",
      "|Allahabad Bank|A-Onerealtors Pvt...|Uttar Pradesh|Allahabad|        Meja|  212303|     F|  7|                1|                 0|                        0|                                1|\n",
      "|Allahabad Bank|Asha Security Gua...|Uttar Pradesh|Sonbhadra| Robertsganj|  231213|     M|  8|                1|                 0|                        0|                                0|\n",
      "|Allahabad Bank|   SGS INDIA PVT LTD|Uttar Pradesh|Sultanpur|   Sultanpur|  227812|     F| 13|                1|                 0|                        0|                                1|\n",
      "|Allahabad Bank|Sri Ramraja Sarka...|Uttar Pradesh|   Shamli|      Shamli|  247775|     M|  6|                1|                 0|                        0|                                1|\n",
      "|Allahabad Bank|  Transmoovers India|Uttar Pradesh|Gorakhpur|    Sahjanwa|  273001|     M|  8|                1|                 0|                        0|                                1|\n",
      "|Allahabad Bank|  Transmoovers India|Uttar Pradesh| Varanasi|      Pindra|  221101|     M| 14|                1|                 0|                        0|                                1|\n",
      "|Allahabad Bank|  Transmoovers India|Uttar Pradesh| Varanasi|    Varanasi|  221001|     M|  9|                1|                 0|                        0|                                1|\n",
      "|Allahabad Bank|  Transmoovers India|Uttar Pradesh| Varanasi|    Varanasi|  221002|     M|  4|                1|                 0|                        0|                                1|\n",
      "|Allahabad Bank|  Transmoovers India|Uttar Pradesh| Varanasi|    Varanasi|  221002|     M| 10|                0|                 1|                        0|                                1|\n",
      "|Allahabad Bank|  Transmoovers India|Uttar Pradesh| Varanasi|    Varanasi|  221002|     M| 19|                1|                 0|                        0|                                1|\n",
      "+--------------+--------------------+-------------+---------+------------+--------+------+---+-----------------+------------------+-------------------------+---------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aadhaar_data=spark_sql_context.read.csv(\"file:///C:/Users/nbhatm/Downloads/Nayana Other stuffs/Edureka Assignments/Datasets/UIDAI-ENR-DETAIL-20170308.csv\",inferSchema=True,header=True)\n",
    "aadhaar_data.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "| total|         State|\n",
      "+------+--------------+\n",
      "|162607|         Bihar|\n",
      "|119901|   West Bengal|\n",
      "|103767| Uttar Pradesh|\n",
      "| 53276|Madhya Pradesh|\n",
      "| 39570|     Rajasthan|\n",
      "| 34844|       Gujarat|\n",
      "| 32485|    Tamil Nadu|\n",
      "| 26085|   Maharashtra|\n",
      "| 19764|     Karnataka|\n",
      "| 18182|        Odisha|\n",
      "| 15143|        Kerala|\n",
      "| 13227|   Uttarakhand|\n",
      "|  9868|     Jharkhand|\n",
      "|  8426|         Delhi|\n",
      "|  6804|       Haryana|\n",
      "|  6604|  Chhattisgarh|\n",
      "|  6506|        Punjab|\n",
      "|  6279|       Mizoram|\n",
      "|  5798|Andhra Pradesh|\n",
      "|  5018|     Telangana|\n",
      "+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+--------------------+\n",
      "| total|    Enrolment Agency|\n",
      "+------+--------------------+\n",
      "|173192|             CSC SPV|\n",
      "| 39619|           Wipro Ltd|\n",
      "| 26497|SREI INFRASTRUCTU...|\n",
      "| 26253|SRM Education And...|\n",
      "| 21823|        Computer LAB|\n",
      "| 20163|Rajcomp Info Serv...|\n",
      "| 17020|    MPOnline Limited|\n",
      "| 16624|AKSH OPTIFIBRE LI...|\n",
      "| 15993|Nielsen  India  P...|\n",
      "| 15981|TAMILNADU ARASU C...|\n",
      "| 14562|             Akshaya|\n",
      "| 13126|   CMS Computers Ltd|\n",
      "| 10644|IAP COMPANY Pvt. Ltd|\n",
      "|  9922|VEETECHNOLOGIES P...|\n",
      "|  9692|NPS Technologies ...|\n",
      "|  8086|Karvy Data Manage...|\n",
      "|  8079|               BASIX|\n",
      "|  7041|A I Soc for Elect...|\n",
      "|  7027|Centre for e-Gove...|\n",
      "|  6946|Zephyr System Pvt...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+---------+-----------------+\n",
      "|malecnt|femalecnt|         district|\n",
      "+-------+---------+-----------------+\n",
      "|   4276|     2859|       Barddhaman|\n",
      "|   3772|     3121|North 24 Parganas|\n",
      "|   3630|     2448|South 24 Parganas|\n",
      "|   3543|     1744|        Bhagalpur|\n",
      "|   3485|     1766|            Patna|\n",
      "|   3460|     1673|            Nadia|\n",
      "|   3018|     1399|      Murshidabad|\n",
      "|   2915|     1487|             Gaya|\n",
      "|   2678|     1388|          Kolkata|\n",
      "|   2622|     1352|          Katihar|\n",
      "|   2522|     1195|       Samastipur|\n",
      "|   2371|     1370|          Bhojpur|\n",
      "|   2265|     1140|           Jaipur|\n",
      "|   2219|     1092|        Ahmedabad|\n",
      "|   2181|     1327|        Bengaluru|\n",
      "|   2174|     1248|         Khagaria|\n",
      "|   2099|      966|   East Champaran|\n",
      "|   2084|      937|   West Champaran|\n",
      "|   2053|     1003|           Munger|\n",
      "|   1933|      618|        Madhubani|\n",
      "+-------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aadhaar_data.createOrReplaceTempView(\"aadhaar_data_tmp\")\n",
    "identities_state=spark_sql_context.sql(\"select Sum(`Aadhaar generated`)as total,State from aadhaar_data_tmp group by State order by total DESC\").show()\n",
    "identities_enrolment=spark_sql_context.sql(\"select Sum(`Aadhaar generated`)as total,`Enrolment Agency` from aadhaar_data_tmp group by `Enrolment Agency` order by total DESC\").show()\n",
    "identities_top_10_district=spark_sql_context.sql(\" select count(case when gender='M' then 1 end) as malecnt,count(case when gender='F' then 1 end) as femalecnt,district from aadhaar_data_tmp group by district order by malecnt DESC,femalecnt DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
